---
layout: page
title: University of Washington Amazon Robot Manipulation
description: 
img: assets/projects/aurmr/preview.png
importance: 1
category: highlight
carousels:
  - images: 
    - image: /assets/projects/aurmr/0_0.png
    - image: /assets/projects/aurmr/0_1.png
    - image: /assets/projects/aurmr/0_2.png
    - image: /assets/projects/aurmr/0_10.png
    - image: /assets/projects/aurmr/0_11.png
  - images: 
    - image: /assets/projects/aurmr/0.png
    - image: /assets/projects/aurmr/1.png
    - image: /assets/projects/aurmr/2.png
    - image: /assets/projects/aurmr/3.png
    - image: /assets/projects/aurmr/4.png
---

<h5 class="row justify-content-sm-center">
University of Washington AURMR Team
</h5>
<h5 class="row justify-content-sm-center">
University of Washington, Seattle
</h5>

## [Data Generation with NVISII](https://github.com/chahyon-ku/aurmr_perception-ku/tree/main/synthetic_data)
Randomized bin of [Google Scanned Objects](https://app.gazebosim.org/GoogleResearch/fuel/collections/Scanned%20Objects%20by%20Google%20Research) <br>
Camera and lighting randomization <br>
Photorealistic RGB + Segmentation Mask + Depth Images

{% include carousel.html height="60" unit="%" duration="10" number="2" %}

## Instance Segmentation for Bin Content Detection
#### [Reimplemented U-Net, FlowNet, ViT Baseline for Semantic Segmentation](https://github.com/chahyon-ku/aurmr_perception-ku/tree/main/object_centric/models)
<!-- Carousel (Ku) -->
##### FlowNet Results
{% include carousel.html height="80" unit="%" duration="10" number="1" %}

## Amazon Picking System
### Integrated ROS + MoveIt + Perception Stack for Bin Picking with UR10
<p align="center"><iframe src="https://www.youtube.com/embed/6EIbJH2UtGU" 
    width="800" 
    height="450"
    frameborder="0" 
    allowfullscreen>
</iframe>
<iframe src="https://www.youtube.com/embed/3T8lP1sRFJs" 
    width="800" 
    height="450"
    frameborder="0" 
    allowfullscreen>
</iframe></p>